# ğŸ§  TDS Virtual TA

A **Virtual Teaching Assistant** API for IIT Madrasâ€™s Data Science Tools (TDS) course.  
It automatically answers student questions using scraped course material and forum posts (Discourse), and exposes a public REST endpoint.

---

## ğŸš€ Features

- **Web Scraper**: Collects course content and Discourse threads (Janâ€“Apr 2025) for contextual understanding.
- **API Endpoint**: Accepts POST requests with student queries and optional base64-encoded images.
- **Automated Responses**: Uses OpenAI GPT models to generate answers and provides relevant Discourse links.
- **Fast & Accurate**: Responds in under 30 seconds and validated using *Promptfoo* against realistic student queries.
- **Deployment-Ready**: Dockerized and deployed via Vercel/Heroku (or your chosen platform). Promptfoo config included.

---

## ğŸ“‚ Project Structure
<pre>
tds-project-1/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ index.py                        # Entry point for FastAPI backend
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ config.py                       # Configuration settings
â”‚   â”œâ”€â”€ main.py                         # App-level initialization and routes
â”‚   â”œâ”€â”€ models.py                       # Pydantic models and schemas
â”‚   â””â”€â”€ rag_pipeline.py                 # Core Retrieval-Augmented Generation logic
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chroma_db/                      # Local vector store (ChromaDB)
â”‚   â”œâ”€â”€ discourse_json/                 # Scraped Discourse data (JSON)
â”‚   â””â”€â”€ tds_pages_md/                   # Course pages content (Markdown format)
â”‚
â”œâ”€â”€ node_modules/                       # Node dependencies (if used in frontend)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_vector_store.py           # Script to build vector DB from scraped data
â”‚   â””â”€â”€ scrape_discourse.py             # Script to scrape Discourse forums
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                      # Basic HTML UI (if applicable)
â”‚
â”œâ”€â”€ Dockerfile                          # Container setup for deployment
â”œâ”€â”€ docker-compose.yml                  # (Optional) Multi-service container config
â”œâ”€â”€ promptfooconfig.yaml                # Promptfoo evaluation config
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ vercel.json                         # Deployment config for Vercel
â”œâ”€â”€ Procfile                            # Heroku deployment entry point
â”œâ”€â”€ LICENSE                             # MIT License
â””â”€â”€ README.md                           # You are here ğŸ“„
</pre>

## âš™ï¸ Getting Started

### Prerequisites

- Python 3.x
- Docker & Docker Compose (if deploying via containers)
- OpenAI API Key

### Setup Steps

1. Clone the repo:
    ```bash
    git clone https://github.com/AdithyaLingam/tds-project-1.git
    cd tds-project-1
    ```
2. Install dependencies:
    ```bash
    pip install -r requirements.txt
    npm install        # if using JS/web files
    ```
3. Add your environment variables in `.env`:
    ```env
    OPENAI_API_KEY=your_openai_key_here
    ```
4. (Optional) Scrape Data:
    ```bash
    python scripts/scrape_discourse.py --start=2025-01-01 --end=2025-04-14
    ```
5. Run Locally:
    ```bash
    uvicorn api.main:app --reload
    ```
6. Test the API:
    ```bash
    curl -X POST https://your-app-url/api/ \
      -H "Content-Type: application/json" \
      -d '{"question":"What is X?","image":"<base64>"}'
    ```

---

## ğŸ” Promptfoo Evaluation

A Promptfoo config is included for automated testing against sample student queries.

```bash
npx promptfoo eval --config promptfooconfig.yaml
promptfoo view


